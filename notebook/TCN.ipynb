{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horoscope generation using Temporal Convolution Networks\n",
    "\n",
    "The goal of this notebook is to implement a generator of horoscope based on neural networks. \n",
    "\n",
    "More specifically, the architecture used is a Temporal Convolution Network based on the research paper [\"An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling\"](https://arxiv.org/abs/1803.01271). This architecture is fully convolutional and can therefore take arbitrary length sequence as inputs. The main idea of the authors of this paper is to increase the perceptive field of each successive layer using [dilated convolution](https://github.com/vdumoulin/conv_arithmetic). \n",
    "\n",
    "The bulk of the code of the TCN has been taken from [the implementation](https://github.com/locuslab/TCN) linked in the article.\n",
    "\n",
    "The data used here are all the horoscopes published [beliefnet.com](beliefnet.com) for the year 2011. \n",
    "\n",
    "The network takes a sequence of `window_size` characters coming from as input and outputs a sequence of `window_size` characters. The target that we use for training is a slice of the horoscope corresponding to the input slid on step to the right, effectively asking the network what should the next character be. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn            as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim         as optim\n",
    "from torch.nn.utils import weight_norm\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda          = True\n",
    "file_path     = '../data/horoscope_2011.csv'\n",
    "window_size   = 150\n",
    "batch_size    = 500\n",
    "print_every   = 500\n",
    "test_seq_size = 600\n",
    "epochs        = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, window_size):\n",
    "    df               = pd.read_csv(path)\n",
    "    text             = ' '.join(df.TEXT).lower()\n",
    "    characters       = set(text)\n",
    "    n_characters     = len(characters)\n",
    "    idx_to_character = dict(enumerate(characters))\n",
    "    character_to_idx = {character : idx for idx, character in idx_to_character.items()}\n",
    "    # As explained above, we use a rolling window on the horoscope text to create our\n",
    "    # training data. An input is the content of window and the corresponding target\n",
    "    # is the content of the window slid one step to the right.\n",
    "    data             = [(text[i : i + window_size], text[i + 1 : i + window_size + 1])\n",
    "                        for i in range(len(text) - window_size - 1)]\n",
    "    \n",
    "    return n_characters, idx_to_character, character_to_idx, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(inp_tensor, length):\n",
    "    # The following lines convert a tensor containing character indentifiers\n",
    "    # into a one hot embedding.\n",
    "    inp_                = torch.unsqueeze(inp_tensor, 2)\n",
    "    batch_size, seq_len = inp_tensor.size()\n",
    "    one_hot             = torch.FloatTensor(batch_size, seq_len, length).zero_()\n",
    "    # As we are using a convolutional network, the expected input is of shape \n",
    "    # (batch, channel, sequence). We have to transpose the tensor that we create\n",
    "    # in order to use the one hot encoding of the characters as channel (dim 1). \n",
    "    one_hot.scatter_(2, inp_, 1).transpose_(1, 2)\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_seq(seq, char_to_id):\n",
    "    return [char_to_id[c] for c in seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_tensor(data, char_to_id, n_char):\n",
    "    input_tensor    = torch.LongTensor([encode_seq(input_seq, char_to_id) \n",
    "                                         for input_seq, _ in data])\n",
    "    one_hot_input   = one_hot_encode(input_tensor, n_char)\n",
    "    target_tensor   = torch.LongTensor([encode_seq(target_seq, char_to_id) \n",
    "                                         for _, target_seq in data])\n",
    "\n",
    "    return one_hot_input, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(data, batch_size, n_char, char_to_id, shuffle = True):\n",
    "    if shuffle:\n",
    "        data = random.sample(data, len(data))\n",
    "    \n",
    "    return (data_to_tensor(data[i : i + batch_size], char_to_id, n_char) \n",
    "                 for i in range(0, len(data), batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model visualization code\n",
    "\n",
    "The model evaluation consists in asking it to generate a long sequence of character. We randomly select an input as a base for our generation and create a new sequence character by character using the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(tcn, final_sequence_size, window_size, n_char, \n",
    "               id_to_char, char_to_id, data):\n",
    "    seq = list(random.choice(data)[0])\n",
    "    while len(seq) < final_sequence_size:\n",
    "        # As the sequence is able to take variable length inputs, it could be \n",
    "        # interesting to not limit ourselves on inputs of window_size.\n",
    "        encoded_input = encode_seq(seq[-window_size:], char_to_id)\n",
    "        input_tensor  = torch.LongTensor([encoded_input])\n",
    "        one_hot_input = one_hot_encode(input_tensor, n_char)\n",
    "        X             = Variable(one_hot_input)\n",
    "        X             = X.cuda() if cuda else X \n",
    "        y_pred        = tcn(X)\n",
    "        # It is important to take the maximum on the dim -2 as each channel of \n",
    "        # the output will correspond to the score associated to a character.\n",
    "        char_pred_id  = y_pred[0].max(dim = -2)[1][-1].cpu().data[0]\n",
    "        char_pred     = id_to_char[char_pred_id]\n",
    "        seq.append(char_pred)\n",
    "    \n",
    "    return ''.join(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function generates an horoscope starting from a `base` supplied by the caller. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genererate_long_sequence(tcn, final_sequence_size, n_char, id_to_char, char_to_id, base):\n",
    "    seq = list(base)\n",
    "\n",
    "    while len(seq) < final_sequence_size:\n",
    "        # In this case we do not limit the size of the input to window_size.\n",
    "        encoded_input = encode_seq(seq, char_to_id)\n",
    "        input_tensor  = torch.LongTensor([encoded_input])\n",
    "        one_hot_input = one_hot_encode(input_tensor, n_char)\n",
    "        X             = Variable(one_hot_input)\n",
    "        X             = X.cuda() if cuda else X \n",
    "        y_pred        = tcn(X)\n",
    "        # It is important to take the maximum on the dim -2 as each channel of \n",
    "        # the output will correspond to the score associated to a character.\n",
    "        char_pred_id  = y_pred[0].max(dim = -2)[1][-1].cpu().data[0]\n",
    "        char_pred     = id_to_char[char_pred_id]\n",
    "        seq.append(char_pred)\n",
    "        \n",
    "    return ''.join(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition\n",
    "\n",
    "The `Chomp1d` module is used to remove the extra values at the end of the sequence by the padding of a convolution. As the TCN architecture uses dilated convolution, the padding have to be increased in order to be able to generate a long enough output. We have to remove the extra values so that the last value of our output is the result of a dilated convolution whose rightmost value was the last value of the input sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # As x can be stored on the GPU, if we use it to build a new tensor,\n",
    "        # we have to ensure that our new value is stored contiguously.\n",
    "        return x[:, :, :-self.chomp_size].contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `TemporalBlock` module is a residual block containing two weight normalized dilated convolutions with ReLU activations and dropout2d (we drop whole channel at once). The residual connection may contain a 1x1 convolution if it is necessary to transform the input to the correct number of channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout = 0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        conv_params = {\n",
    "            'kernel_size' : kernel_size,\n",
    "            'stride'      : stride,\n",
    "            'padding'     : padding,\n",
    "            'dilation'    : dilation\n",
    "        }\n",
    "        self.conv1    = weight_norm(nn.Conv1d(n_inputs, n_outputs, **conv_params))\n",
    "        self.chomp1   = Chomp1d(padding)\n",
    "        self.relu1    = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout2d(dropout)\n",
    "        self.conv2    = weight_norm(nn.Conv1d(n_outputs, n_outputs, **conv_params))\n",
    "        self.chomp2   = Chomp1d(padding)\n",
    "        self.relu2    = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout2d(dropout)\n",
    "        self.net      = nn.Sequential(\n",
    "            self.conv1, \n",
    "            self.chomp1,\n",
    "            self.relu1,\n",
    "            self.dropout1,\n",
    "            self.conv2,\n",
    "            self.chomp2,\n",
    "            self.relu2,\n",
    "            self.dropout2\n",
    "        )\n",
    "        # If the number of input channels is equal to the number of output channel then\n",
    "        # no transformation is required.\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu       = nn.ReLU()\n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Convolutional branch of the residual block\n",
    "        out = self.net(x)\n",
    "        # Residual branch of the residual block\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "\n",
    "        return self.relu(out + res)\n",
    "    \n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Temporal Convolution Network is a sequence of Temporal Blocks whose dilation is doubled at each step. If enough blocks are uses, this definition allows the network to used information for arbitrarily far away in the past to generate its prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size = 2, dropout = 0.2):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers     = []\n",
    "        num_levels = len(num_channels)\n",
    "        \n",
    "        for i in range(num_levels):\n",
    "            # The dilation is doubled at each layer to allow an exponential growth of \n",
    "            # the receptive field size.   \n",
    "            dilation_size = 2 ** i\n",
    "            in_channels   = num_inputs if i == 0 else num_channels[i - 1]\n",
    "            out_channels  = num_channels[i]\n",
    "            layers.append(\n",
    "                TemporalBlock(\n",
    "                    in_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size,\n",
    "                    stride   = 1,\n",
    "                    dilation = dilation_size,\n",
    "                    padding  = (kernel_size - 1) * dilation_size,\n",
    "                    dropout  = dropout\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_char, id_to_char, char_to_id, data = load_data(file_path, window_size)\n",
    "num_channels                         = [512] * 6 + [n_char]\n",
    "tcn                                  = TemporalConvNet(n_char, num_channels)\n",
    "tcn                                  = tcn.cuda() if cuda else tcn\n",
    "# We view the problem as a classification task in which the network tries\n",
    "# to predict what class the following character should be.   \n",
    "criterion                            = nn.CrossEntropyLoss()\n",
    "# We use an Adam optimizer with the default learning rate of 1e-3.\n",
    "optimizer                            = optim.Adam(tcn.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_per_epoch  = math.ceil(len(data) / batch_size)\n",
    "loss_update_rate = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d12b5332a9cd437982d7fbdbe1a89e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epochs', max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e4184b253f64d1c882e8d1cea20b1e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='batches', max=3756), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 49, 150]) torch.Size([500, 150])\n",
      "torch.Size([500, 49, 150]) torch.Size([500, 150])\n",
      "torch.Size([500, 49, 150]) torch.Size([500, 150])\n",
      "torch.Size([500, 49, 150]) torch.Size([500, 150])\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-8105da39b011>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mloss_value\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mloss_pbar\u001b[0m    \u001b[0;34m+=\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mcpu\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mtype\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/_functions/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i, dest_type)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mtype\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CudaBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0m__new__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lazy_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_type\u001b[0;34m(self, new_type, async)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot cast dense tensor to sparse tensor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in tnrange(epochs, desc = 'epochs'):\n",
    "    loss_pbar    = 0 \n",
    "    running_loss = 0\n",
    "    generator    = batch_generator(data, batch_size, n_char, char_to_id)\n",
    "\n",
    "    with tqdm_notebook(\n",
    "        enumerate(generator), \n",
    "        desc = 'batches', \n",
    "        total = batch_per_epoch, \n",
    "        unit = 'batch '\n",
    "    ) as pbar:\n",
    "\n",
    "        for i, (X, y) in pbar:\n",
    "            X = Variable(X)\n",
    "            y = Variable(y)\n",
    "            X = X.cuda() if cuda else X\n",
    "            y = y.cuda() if cuda else y\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = tcn(X)\n",
    "            print(y_pred.size(), y.size())\n",
    "            loss   = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_value    = loss.cpu().data[0]\n",
    "            running_loss += loss_value\n",
    "            loss_pbar    += loss_value\n",
    "\n",
    "            if i % loss_update_rate == loss_update_rate - 1:\n",
    "                pbar.set_postfix(loss = loss_pbar / loss_update_rate)\n",
    "                loss_pbar = 0\n",
    "\n",
    "            if i % print_every == print_every - 1:\n",
    "                test_result = test_model(tcn, test_seq_size, window_size, n_char, \n",
    "                                         id_to_char, char_to_id, data)\n",
    "                tqdm.write(f'Batch: {i + 1 : 6}, '\n",
    "                           f'loss: {running_loss / print_every : .4f}\\n'\n",
    "                           f'{test_result}\\n')\n",
    "                running_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genererate_long_sequence(\n",
    "    tcn, \n",
    "    3000, \n",
    "    n_char, \n",
    "    id_to_char, \n",
    "    char_to_id, \n",
    "    'your day will be terrible but you should stay optimistic because'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
